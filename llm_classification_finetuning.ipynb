{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Step2: Embedding-based Model (public score: 1.03647)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz92v65qWIlL"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-MzD2svWIlM"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "llm_classification_finetuning_path = kagglehub.competition_download('llm-classification-finetuning')\n",
        "shinomoriaoshi_sentencetransformersallminilml6v2_path = kagglehub.dataset_download('shinomoriaoshi/sentencetransformersallminilml6v2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-11-05T04:13:20.015476Z",
          "iopub.status.busy": "2025-11-05T04:13:20.014931Z",
          "iopub.status.idle": "2025-11-05T04:18:15.75803Z",
          "shell.execute_reply": "2025-11-05T04:18:15.756969Z",
          "shell.execute_reply.started": "2025-11-05T04:13:20.01545Z"
        },
        "id": "caH9UI3RWIlN",
        "outputId": "ecae0d9e-6c1f-492f-e1db-d0c2ff80651a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/sentencetransformersallminilml6v2/config.json\n",
            "/kaggle/input/sentencetransformersallminilml6v2/tokenizer.json\n",
            "/kaggle/input/sentencetransformersallminilml6v2/tokenizer_config.json\n",
            "/kaggle/input/sentencetransformersallminilml6v2/pytorch_model.bin\n",
            "/kaggle/input/sentencetransformersallminilml6v2/special_tokens_map.json\n",
            "/kaggle/input/sentencetransformersallminilml6v2/vocab.txt\n",
            "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
            "/kaggle/input/llm-classification-finetuning/train.csv\n",
            "/kaggle/input/llm-classification-finetuning/test.csv\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.0.0rc2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.19.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c456914d3d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c456914e050>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c456914e6d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c456914f050>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c456914fa90>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c4569145390>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torch/\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7c456913ae10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torch/\u001b[0m\u001b[33m\n",
            "\u001b[0m^C\n"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "!pip install sentence-transformers lightgbm pandas numpy\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-05T04:18:18.788154Z",
          "iopub.status.busy": "2025-11-05T04:18:18.78765Z",
          "iopub.status.idle": "2025-11-05T04:18:21.173254Z",
          "shell.execute_reply": "2025-11-05T04:18:21.172675Z",
          "shell.execute_reply.started": "2025-11-05T04:18:18.788131Z"
        },
        "id": "FmL8hEFXWIlN",
        "outputId": "0491384b-f3e3-46e9-ce08-4cfdbb425248",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 데이터 크기: (57477, 9)\n",
            "테스트 데이터 크기: (3, 4)\n"
          ]
        }
      ],
      "source": [
        "# --- 1. 데이터 로드 ---\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# 캐글 환경의 데이터 경로입니다.\n",
        "# 본인의 캐글 노트북 환경에 맞게 경로를 확인하세요.\n",
        "DATA_PATH = \"/kaggle/input/llm-classification-finetuning/\"\n",
        "\n",
        "try:\n",
        "    train_df = pd.read_csv(f\"{DATA_PATH}train.csv\")\n",
        "    test_df = pd.read_csv(f\"{DATA_PATH}test.csv\")\n",
        "    sample_submission_df = pd.read_csv(f\"{DATA_PATH}sample_submission.csv\")\n",
        "\n",
        "    print(f\"학습 데이터 크기: {train_df.shape}\")\n",
        "    print(f\"테스트 데이터 크기: {test_df.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"오류: 캐글 데이터셋 경로({DATA_PATH})를 찾을 수 없습니다.\")\n",
        "    print(\"로컬 환경이거나 경로가 다른 경우, DATA_PATH 변수를 수정해주세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-05T04:18:22.840185Z",
          "iopub.status.busy": "2025-11-05T04:18:22.839514Z",
          "iopub.status.idle": "2025-11-05T04:18:22.859635Z",
          "shell.execute_reply": "2025-11-05T04:18:22.859073Z",
          "shell.execute_reply.started": "2025-11-05T04:18:22.840158Z"
        },
        "id": "QPVzvy8DWIlN",
        "outputId": "801d1be6-cfdf-4a8c-93e0-7d5777dc1570",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "타겟 변수(y_train) 생성 완료.\n",
            "y_train 분포:\n",
            "0    0.349079\n",
            "1    0.341911\n",
            "2    0.309011\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# --- 2. 타겟 변수(y_train) 생성 ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# 'winner_model_a', 'winner_model_b', 'winner_model_tie' 3개 컬럼을\n",
        "# 0, 1, 2 (a, b, tie) 형태의 단일 숫자 레이블로 변환합니다.\n",
        "target_cols = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
        "# np.argmax는 [1, 0, 0] -> 0, [0, 1, 0] -> 1, [0, 0, 1] -> 2로 바꿔줍니다.\n",
        "y_train = np.argmax(train_df[target_cols].values, axis=1)\n",
        "\n",
        "print(\"\\n타겟 변수(y_train) 생성 완료.\")\n",
        "print(f\"y_train 분포:\\n{pd.Series(y_train).value_counts(normalize=True)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-05T04:10:14.782212Z",
          "iopub.status.busy": "2025-11-05T04:10:14.781461Z",
          "iopub.status.idle": "2025-11-05T04:10:14.944375Z",
          "shell.execute_reply": "2025-11-05T04:10:14.943552Z",
          "shell.execute_reply.started": "2025-11-05T04:10:14.782187Z"
        },
        "id": "NAP1ebqiWIlO",
        "outputId": "46491dee-5847-4fc3-befb-4029c0a9a152",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 89700\n",
            "drwxr-xr-x 2 nobody nogroup        0 Oct 29 10:54 .\n",
            "drwxr-xr-x 4 root   root        4096 Nov  5 04:04 ..\n",
            "-rw-r--r-- 1 nobody nogroup      678 Oct 29 10:54 config.json\n",
            "-rw-r--r-- 1 nobody nogroup 90890157 Oct 29 10:54 pytorch_model.bin\n",
            "-rw-r--r-- 1 nobody nogroup      125 Oct 29 10:54 special_tokens_map.json\n",
            "-rw-r--r-- 1 nobody nogroup      570 Oct 29 10:54 tokenizer_config.json\n",
            "-rw-r--r-- 1 nobody nogroup   711661 Oct 29 10:54 tokenizer.json\n",
            "-rw-r--r-- 1 nobody nogroup   231508 Oct 29 10:54 vocab.txt\n"
          ]
        }
      ],
      "source": [
        "!ls -al /kaggle/input/sentencetransformersallminilml6v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "6a565fa1255e4364ab6881e2cf0a40f3",
            "ed2860213af3434f981a266313b8a53a",
            "3bd2fff27ca9436f9613dbc47f223f1f",
            "84a17eadc5554a99986b15b0f9bc430e",
            "f40fa7f270cc4df7a3de22281e834407",
            "4898e1c6cd99472799ac0cc58fb528ad"
          ]
        },
        "execution": {
          "iopub.execute_input": "2025-11-05T04:22:13.83498Z",
          "iopub.status.busy": "2025-11-05T04:22:13.834218Z",
          "iopub.status.idle": "2025-11-05T04:31:19.51446Z",
          "shell.execute_reply": "2025-11-05T04:31:19.513865Z",
          "shell.execute_reply.started": "2025-11-05T04:22:13.834951Z"
        },
        "id": "nGF48g6FWIlO",
        "outputId": "1ff77edc-7187-41ad-b02d-8a480df3eea7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "임베딩 모델 로드 중... (로컬 경로: /kaggle/input/sentencetransformersallminilml6v2)\n",
            "모델 로드 완료.\n",
            "모델 로드 완료.\n",
            "총 57477개의 데이터 임베딩 생성 중...\n",
            "Prompt 임베딩 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a565fa1255e4364ab6881e2cf0a40f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1797 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response A 임베딩 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed2860213af3434f981a266313b8a53a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1797 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response B 임베딩 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bd2fff27ca9436f9613dbc47f223f1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1797 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 피처 행렬 크기: (57477, 1920)\n",
            "총 3개의 데이터 임베딩 생성 중...\n",
            "Prompt 임베딩 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84a17eadc5554a99986b15b0f9bc430e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response A 임베딩 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f40fa7f270cc4df7a3de22281e834407",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response B 임베딩 중...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4898e1c6cd99472799ac0cc58fb528ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 피처 행렬 크기: (3, 1920)\n"
          ]
        }
      ],
      "source": [
        "# --- 3. 임베딩 모델 로드 ---\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "MODEL_PATH = \"/kaggle/input/sentencetransformersallminilml6v2\"\n",
        "# 'all-MiniLM-L6-v2'는 작고 빠르며 준수한 성능을 내는 모델입니다.\n",
        "print(f\"\\n임베딩 모델 로드 중... (로컬 경로: {MODEL_PATH})\")\n",
        "\n",
        "try:\n",
        "    embedding_model = SentenceTransformer(\n",
        "        MODEL_PATH,\n",
        "        device='cuda',\n",
        "        # 1. local_files_only=True : 인터넷(Hugging Face Hub) 조회를 강제로 차단합니다.\n",
        "        local_files_only=True,\n",
        "        # 2. tokenizer_kwargs : 'additional_chat_templates' 404 오류를 우회합니다.\n",
        "        tokenizer_kwargs={\"chat_template\": None}\n",
        "    )\n",
        "    print(\"모델 로드 완료.\")\n",
        "\n",
        "except OSError:\n",
        "    print(f\"오류: {MODEL_PATH} 경로에 모델이 없습니다.\")\n",
        "    print(\"오른쪽 'Add Data'에서 'sentence-transformers/all-minilm-l6-v2' 데이터셋을 추가했는지 확인하세요.\")\n",
        "    # 오류 발생 시에도 스크립트가 멈추지 않도록 예외 처리\n",
        "    raise Exception(\"모델 로드 실패. 캐글 데이터셋을 추가하세요.\")\n",
        "\n",
        "print(\"모델 로드 완료.\")\n",
        "\n",
        "# --- 4. 텍스트 임베딩 생성 함수 ---\n",
        "def get_embeddings(df, model):\n",
        "    print(f\"총 {len(df)}개의 데이터 임베딩 생성 중...\")\n",
        "\n",
        "    # 각 텍스트 컬럼을 리스트로 변환\n",
        "    prompts = df['prompt'].tolist()\n",
        "    responses_a = df['response_a'].tolist()\n",
        "    responses_b = df['response_b'].tolist()\n",
        "\n",
        "    # 모델로 임베딩\n",
        "    print(\"Prompt 임베딩 중...\")\n",
        "    prompt_emb = model.encode(prompts, show_progress_bar=True, device='cuda')\n",
        "    print(\"Response A 임베딩 중...\")\n",
        "    resp_a_emb = model.encode(responses_a, show_progress_bar=True, device='cuda')\n",
        "    print(\"Response B 임베딩 중...\")\n",
        "    resp_b_emb = model.encode(responses_b, show_progress_bar=True, device='cuda')\n",
        "\n",
        "    return prompt_emb, resp_a_emb, resp_b_emb\n",
        "\n",
        "# --- 5. 피처(X) 생성 함수 ---\n",
        "# A vs B 비교 문제에서는 각 임베딩을 합치는(concatenate) 것 외에도\n",
        "# A와 B의 차이(difference), 곱(element-wise product)을 피처로 넣어주면 성능이 향상됩니다.\n",
        "def create_features(prompt_emb, resp_a_emb, resp_b_emb):\n",
        "    diff_emb = resp_a_emb - resp_b_emb\n",
        "    prod_emb = resp_a_emb * resp_b_emb\n",
        "\n",
        "    # (prompt, resp_a, resp_b, a-b, a*b) 5개 임베딩을 가로로 연결\n",
        "    features = np.concatenate([\n",
        "        prompt_emb,\n",
        "        resp_a_emb,\n",
        "        resp_b_emb,\n",
        "        diff_emb,\n",
        "        prod_emb\n",
        "    ], axis=1)\n",
        "\n",
        "    return features\n",
        "\n",
        "# 학습 데이터 피처 생성\n",
        "train_prompt_emb, train_resp_a_emb, train_resp_b_emb = get_embeddings(train_df, embedding_model)\n",
        "X_train_features = create_features(train_prompt_emb, train_resp_a_emb, train_resp_b_emb)\n",
        "\n",
        "print(f\"학습 피처 행렬 크기: {X_train_features.shape}\") # (n_samples, 384 * 5)\n",
        "\n",
        "# 테스트 데이터 피처 생성\n",
        "test_prompt_emb, test_resp_a_emb, test_resp_b_emb = get_embeddings(test_df, embedding_model)\n",
        "X_test_features = create_features(test_prompt_emb, test_resp_a_emb, test_resp_b_emb)\n",
        "\n",
        "print(f\"테스트 피처 행렬 크기: {X_test_features.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-05T04:44:01.563896Z",
          "iopub.status.busy": "2025-11-05T04:44:01.563192Z",
          "iopub.status.idle": "2025-11-05T04:46:45.025651Z",
          "shell.execute_reply": "2025-11-05T04:46:45.02483Z",
          "shell.execute_reply.started": "2025-11-05T04:44:01.563861Z"
        },
        "id": "z0AcCE7XWIlO",
        "outputId": "905c7e6e-5387-4a85-bf1a-fb9aebbba9e8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "LightGBM 모델 학습 시작...\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 489090\n",
            "[LightGBM] [Info] Number of data points in the train set: 57477, number of used features: 1918\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 1918 dense feature groups (105.24 MB) transferred to GPU in 0.099271 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] Start training from score -1.052458\n",
            "[LightGBM] [Info] Start training from score -1.073206\n",
            "[LightGBM] [Info] Start training from score -1.174380\n",
            "모델 학습 완료.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import log_loss\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# --- 6. 분류 모델 학습 (LightGBM) ---\n",
        "print(\"\\nLightGBM 모델 학습 시작...\")\n",
        "\n",
        "# K-Fold 교차 검증을 사용하는 것이 훨씬 안정적이고 좋지만,\n",
        "# 우선 전체 데이터로 학습합니다.\n",
        "lgb_classifier = lgb.LGBMClassifier(\n",
        "    objective='multiclass',  # 다중 분류 (a, b, tie)\n",
        "    metric='multi_logloss',  # 대회의 평가 지표\n",
        "    num_class=3,             # 클래스 개수 (0, 1, 2)\n",
        "    random_state=42,\n",
        "    n_estimators=300,        # 트리의 개수 (튜닝 필요)\n",
        "    learning_rate=0.03,      # 학습률 (튜닝 필요)\n",
        "    num_leaves=31,           # 리프 노드의 수 (튜닝 필요)\n",
        "    device='gpu'\n",
        "    # n_jobs=-1                # 모든 CPU 코어 사용\n",
        ")\n",
        "\n",
        "lgb_classifier.fit(X_train_features, y_train)\n",
        "\n",
        "print(\"모델 학습 완료.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-11-05T04:48:07.266852Z",
          "iopub.status.busy": "2025-11-05T04:48:07.265901Z",
          "iopub.status.idle": "2025-11-05T04:48:07.28193Z",
          "shell.execute_reply": "2025-11-05T04:48:07.281188Z",
          "shell.execute_reply.started": "2025-11-05T04:48:07.26682Z"
        },
        "id": "xn0z313aWIlO",
        "outputId": "a76eafd4-a7fc-4762-f261-4a3b33108291",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 데이터로 예측 수행 중...\n",
            "예측 완료.\n",
            "제출 파일(submission.csv) 생성 중...\n",
            "\n",
            "'submission.csv' 파일이 성공적으로 생성되었습니다.\n",
            "캐글에 이 파일을 제출하여 Step 2 점수를 확인하세요!\n",
            "\n",
            "--- 스크립트 종료 ---\n"
          ]
        }
      ],
      "source": [
        "# --- 7. 예측 ---\n",
        "print(\"테스트 데이터로 예측 수행 중...\")\n",
        "# Log Loss 평가를 위해 각 클래스(a, b, tie)의 확률을 예측합니다.\n",
        "# test_probabilities는 (n_test_samples, 3) 크기의 배열이 됩니다.\n",
        "test_probabilities = lgb_classifier.predict_proba(X_test_features)\n",
        "\n",
        "print(\"예측 완료.\")\n",
        "\n",
        "# --- 8. 제출 파일 생성 ---\n",
        "print(\"제출 파일(submission.csv) 생성 중...\")\n",
        "\n",
        "# sample_submission.csv는 id만 사용하고, 3개의 확률 컬럼을 추가합니다.\n",
        "submission_df = pd.DataFrame({'id': test_df['id']})\n",
        "submission_df['winner_model_a'] = test_probabilities[:, 0]  # 클래스 0 (a)의 확률\n",
        "submission_df['winner_model_b'] = test_probabilities[:, 1]  # 클래스 1 (b)의 확률\n",
        "submission_df['winner_model_tie'] = test_probabilities[:, 2]  # 클래스 2 (tie)의 확률\n",
        "\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\n'submission.csv' 파일이 성공적으로 생성되었습니다.\")\n",
        "print(\"캐글에 이 파일을 제출하여 Step 2 점수를 확인하세요!\")\n",
        "\n",
        "print(\"\\n--- 스크립트 종료 ---\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "llm-classification-finetuning",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 9809560,
          "isSourceIdPinned": false,
          "sourceId": 86518,
          "sourceType": "competition"
        },
        {
          "datasetId": 2804156,
          "sourceId": 4838716,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31153,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
